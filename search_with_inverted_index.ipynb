{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = pd.read_json(\"processed_text.json\")\n",
    "processed_text_tf_idf = pd.read_json(\"processed_text_tf_idf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tfidf_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pandemic</td>\n",
       "      <td>A pandemic (from Greek πᾶν, pan, \"all\" and δῆμ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pandemic</td>\n",
       "      <td>[pandemic, greek, pan, demo, people, epidemic,...</td>\n",
       "      <td>{'pandemic': 0.0504098705, 'greek': 3.25809653...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epidemiology of HIV/AIDS</td>\n",
       "      <td>HIV/AIDS, or Human Immunodeficiency Virus, is ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Epidemiology_of_...</td>\n",
       "      <td>[hiv, aids, human, immunodeficiency, virus, co...</td>\n",
       "      <td>{'pandemic': 0.0144028201, 'greek': 0.0, 'pan'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonine Plague</td>\n",
       "      <td>The Antonine Plague of 165 to 180 AD, also kno...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Antonine_Plague</td>\n",
       "      <td>[plague, ad, know, plague, galen, galen, physi...</td>\n",
       "      <td>{'pandemic': 0.0144028201, 'greek': 0.0, 'pan'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basic reproduction number</td>\n",
       "      <td>In epidemiology, the basic reproduction number...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Basic_reproducti...</td>\n",
       "      <td>[epidemiology, basic, reproduction, number, ba...</td>\n",
       "      <td>{'pandemic': 0.0, 'greek': 0.0, 'pan': 0.0, 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bills of mortality</td>\n",
       "      <td>Bills of mortality were the weekly mortality s...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bills_of_mortality</td>\n",
       "      <td>[bill, mortality, weekly, mortality, statistic...</td>\n",
       "      <td>{'pandemic': 0.0, 'greek': 0.0, 'pan': 0.0, 'd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  \\\n",
       "0                   Pandemic   \n",
       "1   Epidemiology of HIV/AIDS   \n",
       "2            Antonine Plague   \n",
       "3  Basic reproduction number   \n",
       "4         Bills of mortality   \n",
       "\n",
       "                                                text  \\\n",
       "0  A pandemic (from Greek πᾶν, pan, \"all\" and δῆμ...   \n",
       "1  HIV/AIDS, or Human Immunodeficiency Virus, is ...   \n",
       "2  The Antonine Plague of 165 to 180 AD, also kno...   \n",
       "3  In epidemiology, the basic reproduction number...   \n",
       "4  Bills of mortality were the weekly mortality s...   \n",
       "\n",
       "                                                 url  \\\n",
       "0             https://en.wikipedia.org/wiki/Pandemic   \n",
       "1  https://en.wikipedia.org/wiki/Epidemiology_of_...   \n",
       "2      https://en.wikipedia.org/wiki/Antonine_Plague   \n",
       "3  https://en.wikipedia.org/wiki/Basic_reproducti...   \n",
       "4   https://en.wikipedia.org/wiki/Bills_of_mortality   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [pandemic, greek, pan, demo, people, epidemic,...   \n",
       "1  [hiv, aids, human, immunodeficiency, virus, co...   \n",
       "2  [plague, ad, know, plague, galen, galen, physi...   \n",
       "3  [epidemiology, basic, reproduction, number, ba...   \n",
       "4  [bill, mortality, weekly, mortality, statistic...   \n",
       "\n",
       "                                        tfidf_vector  \n",
       "0  {'pandemic': 0.0504098705, 'greek': 3.25809653...  \n",
       "1  {'pandemic': 0.0144028201, 'greek': 0.0, 'pan'...  \n",
       "2  {'pandemic': 0.0144028201, 'greek': 0.0, 'pan'...  \n",
       "3  {'pandemic': 0.0, 'greek': 0.0, 'pan': 0.0, 'd...  \n",
       "4  {'pandemic': 0.0, 'greek': 0.0, 'pan': 0.0, 'd...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text_tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary \n",
    "# vocab dict contains 'cornovirus' but the lemmatized verion is turning into 'coronaviru'\n",
    "vocab = set([word for document in processed_text_tf_idf.processed_text for word in document])\n",
    "vocab_dict = {word:[] for word in vocab}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inverse Document object\n",
    "for idx, document_idf in enumerate(processed_text_tf_idf.tfidf_vector):\n",
    "    for key, value in document_idf.items():\n",
    "        if value > 0:\n",
    "            vocab_dict[key].append((processed_text.title[idx], value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a search funciton\n",
    "# 1. Tokenize the new phrase\n",
    "# 2. Filter to words in the dictionary that are in the phrase\n",
    "# 3. Sum grouped by the documents to get the highest tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query_tokens(text, vocab = vocab):\n",
    "    \"\"\" Accepts any list of words and returns a tokenized list\n",
    "\n",
    "    Args:\n",
    "        text (string):\n",
    "\n",
    "    Returns:\n",
    "        list: Tokenizeed list of lemmatized words\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_lg\") # Initialize the vocabulary\n",
    "    doc = nlp(text.lower())\n",
    "    filtered_sentence =[] \n",
    "    for word in doc:\n",
    "        lexeme = nlp.vocab[str(word)]\n",
    "        if lexeme.is_stop == False and lexeme.is_punct == False and lexeme.is_oov == False and lexeme.lower_ in vocab:\n",
    "            filtered_sentence.append(word.lemma_) \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_search_term = make_query_tokens(\"coronavirus\")\n",
    "tokenized_search_term\n",
    "# Need to implment fix here to check if search word in vocab\n",
    "#relavent_documents_dictionary = {token:vocab_dict[token] for token in tokenized_search_term}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index_search(search_string:str, inverted_index = vocab_dict):\n",
    "    \"\"\"Accept a search string and an inverted index, return the most sorted search results in teh form of a dataframe\n",
    "\n",
    "    Args:\n",
    "        search_string (str): _description_\n",
    "        inverted_index (_type_): _description_\n",
    "    \"\"\"\n",
    "    tokenized_search_term = make_query_tokens(search_string)\n",
    "    relavent_documents_dictionary = {token:vocab_dict[token] for token in tokenized_search_term}\n",
    "    \n",
    "    search_results = pd.DataFrame([doc for word in list(relavent_documents_dictionary.values()) for doc in word],\n",
    "             columns=[\"title\", \"tf_idf_score\"]).groupby(\"title\").sum().sort_values(by = 'tf_idf_score', ascending = False)\n",
    "    \n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COVID-19 pandemic</th>\n",
       "      <td>6.935147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swine influenza</th>\n",
       "      <td>0.837907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholera</th>\n",
       "      <td>0.418953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <td>0.418953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIV/AIDS in Yunnan</th>\n",
       "      <td>0.418953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virus</th>\n",
       "      <td>0.418953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tf_idf_score\n",
       "title                           \n",
       "COVID-19 pandemic       6.935147\n",
       "Swine influenza         0.837907\n",
       "Cholera                 0.418953\n",
       "HIV/AIDS                0.418953\n",
       "HIV/AIDS in Yunnan      0.418953\n",
       "Virus                   0.418953"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index_search(\"common symptoms of coronavirus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce6b2e46da96f80237154c4d39870d1180913a52ccea59b3717ca4730176c7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
