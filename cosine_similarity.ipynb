{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Search Using Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pandemic</td>\n",
       "      <td>A pandemic (from Greek πᾶν, pan, \"all\" and δῆμ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pandemic</td>\n",
       "      <td>[pandemic, greek, pan, demo, people, epidemic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epidemiology of HIV/AIDS</td>\n",
       "      <td>HIV/AIDS, or Human Immunodeficiency Virus, is ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Epidemiology_of_...</td>\n",
       "      <td>[hiv, aid, human, immunodeficiency, virus, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonine Plague</td>\n",
       "      <td>The Antonine Plague of 165 to 180 AD, also kno...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Antonine_Plague</td>\n",
       "      <td>[plague, 165, 180, ad, know, plague, galen, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basic reproduction number</td>\n",
       "      <td>In epidemiology, the basic reproduction number...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Basic_reproducti...</td>\n",
       "      <td>[epidemiology, basic, reproduction, number, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bills of mortality</td>\n",
       "      <td>Bills of mortality were the weekly mortality s...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bills_of_mortality</td>\n",
       "      <td>[bill, mortality, weekly, mortality, statistic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  \\\n",
       "0                   Pandemic   \n",
       "1   Epidemiology of HIV/AIDS   \n",
       "2            Antonine Plague   \n",
       "3  Basic reproduction number   \n",
       "4         Bills of mortality   \n",
       "\n",
       "                                                text  \\\n",
       "0  A pandemic (from Greek πᾶν, pan, \"all\" and δῆμ...   \n",
       "1  HIV/AIDS, or Human Immunodeficiency Virus, is ...   \n",
       "2  The Antonine Plague of 165 to 180 AD, also kno...   \n",
       "3  In epidemiology, the basic reproduction number...   \n",
       "4  Bills of mortality were the weekly mortality s...   \n",
       "\n",
       "                                                 url  \\\n",
       "0             https://en.wikipedia.org/wiki/Pandemic   \n",
       "1  https://en.wikipedia.org/wiki/Epidemiology_of_...   \n",
       "2      https://en.wikipedia.org/wiki/Antonine_Plague   \n",
       "3  https://en.wikipedia.org/wiki/Basic_reproducti...   \n",
       "4   https://en.wikipedia.org/wiki/Bills_of_mortality   \n",
       "\n",
       "                                      processed_text  \n",
       "0  [pandemic, greek, pan, demo, people, epidemic,...  \n",
       "1  [hiv, aid, human, immunodeficiency, virus, con...  \n",
       "2  [plague, 165, 180, ad, know, plague, galen, ga...  \n",
       "3  [epidemiology, basic, reproduction, number, ba...  \n",
       "4  [bill, mortality, weekly, mortality, statistic...  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_json(\"processed_text.json\")\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency\n",
    "\n",
    "**The number of times a word appears in a document divided by the total times it appears in the corpus. Every document has its own term frequency.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(single_doc, docs):\n",
    "    \"\"\"Computes the Term Frequency given the tokenized text string doc and a list of tokenized documents all_docs. Returns a complete vocabulary of all_docs as a  dictionary of words with number of word appearances in doc divided by number of word appearances in all_docs\n",
    "\n",
    "    Args:\n",
    "        doc (list): A preprocessed text string tokenized into a list of words\n",
    "        all_docs (list): A list of tokenized text strings now represented as word lists\n",
    "    \"\"\"\n",
    "    doc_counts = Counter(single_doc)\n",
    "    corpus = [word for sublist in docs for word in sublist]\n",
    "    corpus_counts = Counter(corpus)\n",
    "    tf_dict = dict.fromkeys(corpus, 0)\n",
    "    for key in doc_counts.keys():\n",
    "       tf_dict[key] = doc_counts[key]/corpus_counts[key]\n",
    "      \n",
    "    return(tf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency\n",
    "\n",
    "**The number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docs):    \n",
    "    \"\"\" Accepts a list of documents and returns the number of total documents divided by the number of documents containing a given word for each word\n",
    "    Args:\n",
    "        doc (list): A list of tokenized text strings now represented as word lists\n",
    "    \"\"\"\n",
    "    N = len(docs)\n",
    "    corpus = [word for sublist in docs for word in sublist]\n",
    "    idfDict = dict.fromkeys(corpus, 0)\n",
    "    for document in docs:\n",
    "        for word in list(set(document)):\n",
    "            idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = N/float(val)\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting TF and IDF together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Inverse Document Frequency\n",
    "def build_tf_idf(doc, docs):\n",
    "    \"\"\"Given a preprocessed string and a list of documents returns the TF-IDF vectorization\n",
    "\n",
    "    Args:\n",
    "        doc (list): A tokenized list of words\n",
    "        docs (list): A list of tokenized documents that make up entire vocab\n",
    "    \"\"\"\n",
    "\n",
    "    tf_idf_vector = []\n",
    "    tf_dict = computeTF(doc, docs)\n",
    "    idf_dict = computeIDF(docs)\n",
    "\n",
    "    for word, val in tf_dict.items():\n",
    "        tf_idf_vector.append(tf_dict[word]*idf_dict[word])\n",
    "    \n",
    "    return np.array([tf_idf_vector])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tfidf_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pandemic</td>\n",
       "      <td>A pandemic (from Greek πᾶν, pan, \"all\" and δῆμ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pandemic</td>\n",
       "      <td>[pandemic, greek, pan, demo, people, epidemic,...</td>\n",
       "      <td>[[0.1814556331006979, 26.0, 26.0, 26.0, 0.4075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epidemiology of HIV/AIDS</td>\n",
       "      <td>HIV/AIDS, or Human Immunodeficiency Virus, is ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Epidemiology_of_...</td>\n",
       "      <td>[hiv, aid, human, immunodeficiency, virus, con...</td>\n",
       "      <td>[[0.051844466600199396, 0.0, 0.0, 0.0, 0.65203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonine Plague</td>\n",
       "      <td>The Antonine Plague of 165 to 180 AD, also kno...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Antonine_Plague</td>\n",
       "      <td>[plague, 165, 180, ad, know, plague, galen, ga...</td>\n",
       "      <td>[[0.051844466600199396, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basic reproduction number</td>\n",
       "      <td>In epidemiology, the basic reproduction number...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Basic_reproducti...</td>\n",
       "      <td>[epidemiology, basic, reproduction, number, ba...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.2445141065830721, 0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bills of mortality</td>\n",
       "      <td>Bills of mortality were the weekly mortality s...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bills_of_mortality</td>\n",
       "      <td>[bill, mortality, weekly, mortality, statistic...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  \\\n",
       "0                   Pandemic   \n",
       "1   Epidemiology of HIV/AIDS   \n",
       "2            Antonine Plague   \n",
       "3  Basic reproduction number   \n",
       "4         Bills of mortality   \n",
       "\n",
       "                                                text  \\\n",
       "0  A pandemic (from Greek πᾶν, pan, \"all\" and δῆμ...   \n",
       "1  HIV/AIDS, or Human Immunodeficiency Virus, is ...   \n",
       "2  The Antonine Plague of 165 to 180 AD, also kno...   \n",
       "3  In epidemiology, the basic reproduction number...   \n",
       "4  Bills of mortality were the weekly mortality s...   \n",
       "\n",
       "                                                 url  \\\n",
       "0             https://en.wikipedia.org/wiki/Pandemic   \n",
       "1  https://en.wikipedia.org/wiki/Epidemiology_of_...   \n",
       "2      https://en.wikipedia.org/wiki/Antonine_Plague   \n",
       "3  https://en.wikipedia.org/wiki/Basic_reproducti...   \n",
       "4   https://en.wikipedia.org/wiki/Bills_of_mortality   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [pandemic, greek, pan, demo, people, epidemic,...   \n",
       "1  [hiv, aid, human, immunodeficiency, virus, con...   \n",
       "2  [plague, 165, 180, ad, know, plague, galen, ga...   \n",
       "3  [epidemiology, basic, reproduction, number, ba...   \n",
       "4  [bill, mortality, weekly, mortality, statistic...   \n",
       "\n",
       "                                        tfidf_vector  \n",
       "0  [[0.1814556331006979, 26.0, 26.0, 26.0, 0.4075...  \n",
       "1  [[0.051844466600199396, 0.0, 0.0, 0.0, 0.65203...  \n",
       "2  [[0.051844466600199396, 0.0, 0.0, 0.0, 0.0, 0....  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.2445141065830721, 0.23...  \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[\"tfidf_vector\"] = text_df.processed_text.apply(build_tf_idf, docs=text_df.processed_text)\n",
    "text_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tf_idf = text_df.to_json()\n",
    "\n",
    "with open('processed_text_tf_idf.json', 'w') as outfile:\n",
    "    outfile.write(text_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Search Function using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(text):\n",
    "    \"\"\" Accepts any list of words and returns a tokenized list\n",
    "\n",
    "    Args:\n",
    "        text (string):\n",
    "\n",
    "    Returns:\n",
    "        list: Tokenizeed list of lemmatized words\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_lg\") # Initialize the vocabulary\n",
    "    doc = nlp(text.lower())\n",
    "    filtered_sentence =[] \n",
    "    for word in doc:\n",
    "        lexeme = nlp.vocab[str(word)]\n",
    "        if lexeme.is_stop == False and lexeme.is_punct == False and lexeme.is_oov == False:\n",
    "            filtered_sentence.append(word.lemma_) \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarites(string, titles, documents):\n",
    "    \"\"\"Accepts a string, list of title, documents, and a tfidf vector returns a dictionary of title with cosine similarity score ordered by most similar to least similar\n",
    "\n",
    "    Args:\n",
    "        string (string): Any string of words\n",
    "        titles (list): A list of document titles associated with the  vectorized documents given in the tfidf_vector argument\n",
    "        documents (list): A list of preprocessed document token vectors to build vocabularity for tf-idf computation\n",
    "    \"\"\"\n",
    "    tokenized_string = make_tokens(string)\n",
    "    input_tfidf = build_tf_idf(tokenized_string, documents)\n",
    "    document_tf_idf = documents.apply(build_tf_idf, docs = documents)\n",
    "    similarity_scores = document_tf_idf.apply(cosine_similarity, Y=input_tfidf)\n",
    "    similarity_scores = pd.Series([value.item(0) for value in similarity_scores])\n",
    "    scores_df = pd.concat([titles, similarity_scores.rename(\"similarity_score\")], axis=1)\n",
    "    sorted_scores = scores_df.sort_values(by = \"similarity_score\", ascending=False)\n",
    "    sorted_scores_dict = sorted_scores.set_index(\"title\")['similarity_score'].to_dict()\n",
    "    return sorted_scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pandemic': 0.06565558725854108,\n",
       " 'Basic reproduction number': 0.033290824728296475,\n",
       " 'Pandemic Severity Assessment Framework': 8.929262843994132e-06,\n",
       " 'Pandemic prevention': 8.351490595603745e-06,\n",
       " 'Spanish flu': 4.372285738324518e-06,\n",
       " 'Pandemic severity index': 3.7528055360211115e-06,\n",
       " 'Crimson Contagion': 2.6038100054441897e-06,\n",
       " 'COVID-19 pandemic': 2.1369603123478045e-06,\n",
       " 'Swine influenza': 2.0041483019786735e-06,\n",
       " 'PREDICT (USAID)': 1.738603970628896e-06,\n",
       " 'Plague of Cyprian': 1.6761361914768993e-06,\n",
       " '1929–1930 psittacosis pandemic': 1.381880823369405e-06,\n",
       " 'Antonine Plague': 1.1680584605151936e-06,\n",
       " 'Epidemiology of HIV/AIDS': 9.815116466066015e-07,\n",
       " 'Science diplomacy and pandemics': 7.48822242187819e-07,\n",
       " 'Unified Victim Identification System': 5.879564733620065e-07,\n",
       " 'HIV/AIDS': 4.804674146241873e-07,\n",
       " 'Cholera': 4.5097143169457477e-07,\n",
       " 'Bills of mortality': 0.0,\n",
       " 'HIV/AIDS in Yunnan': 0.0,\n",
       " 'Event 201': 0.0,\n",
       " 'Disease X': 0.0,\n",
       " 'Superspreader': 0.0,\n",
       " 'Targeted immunization strategies': 0.0,\n",
       " 'Viral load': 0.0,\n",
       " 'Virus': 0.0}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cosine_similarites(\"Current Covid-19 Pandemic\", text_df.title, text_df.processed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce6b2e46da96f80237154c4d39870d1180913a52ccea59b3717ca4730176c7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
